<h1>Logistic Regression (Classification)</h1>
<p>Using logistic regression to specify qualified students for a department using their scores in two different exams. and Another test on microships tests</p>
<h2>Methods</h2>
<h3>Using Gradient Descent</h3>
</br>
<img src="https://cdn-images-1.medium.com/max/1600/0*8yzvd7QZLn5T1XWg.jpg"/>
</br>
<p>
Initial Theta: <b>0</b></br>
Alpha: <b>0.0001</b></br>
Iteraion: <b>1~10k</b></br>
</br>
<img src ="https://i.imgur.com/HwfT0Bk.png"/>
</br>
<img src="https://i.imgur.com/GTFUHln.png"/>
</br>
<h3>Using Advanced Optimizer</h3>
Iteraion: <b>300</b></br>
</br>
<img = src="https://i.imgur.com/PBX4obJ.png"/>
</br>
<h3>Using Regularization</h3>
<p>Using cost function/gredient/advanced optimization with regularization method</p>
</br>
<img src="http://pingax.com/wp-content/uploads/2014/05/regularized-gradient.png"/>
<h4>Result</h2>
<p>Get a little bit changing with no affection</p>
<p><b>Advanced Optimization</b></p>
</br>
<img src="https://i.imgur.com/NIfb84X.png"/>
</br>
<h2>Optimizing using polynomial regression(Rescaling & Normalization)</h3>
<p>Using <b>second polynomial order</b> to get obtimizer collecting for the right data with scaling and normalization features</p>
<h3>Gradient Descent Result</h2>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>10</b></br></p>
</br>
<img src="https://i.imgur.com/rX287Lk.png"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>100</b></br></p>
</br>
<img src="https://i.imgur.com/VcQwnky.png"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>1k</b></br></p>
</br>
<img src="https://i.imgur.com/sPDOrvZ.png"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>10k</b></br></p>
Last cost: <b>11.595</b>
</br>
<img src="https://i.imgur.com/fxaxZk1.png"/>
</br>
<h3>Advanced Optimization Methods Result</h2>
<p>Initial Theta: <b>0.3</b></br>
Iteraion: <b>300</b></br></p>
Last cost: <b>0.031571</b>
</br>
<img src="https://i.imgur.com/8d5MZpx.png"/>
</br>
<img src="https://i.imgur.com/sfhBliP.png"/>
</br>
<h3>Microship Test (Another Data) Using Gradient Descent</h3>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>10</b></br></p>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584370-95955e00-ca62-11e8-8b6c-84c8fa617103.PNG"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>50</b></br></p>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584379-a514a700-ca62-11e8-9aaa-c964223f3f93.PNG"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>100</b></br></p>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584380-a514a700-ca62-11e8-8f81-c34d83aa40ed.PNG"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>500</b></br></p>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584377-a47c1080-ca62-11e8-9cf3-adcc209f4d9b.PNG"/>
</br>
<p>Initial Theta: <b>0.3</b></br>
Alpha: <b>1</b></br>
Iteraion: <b>1000</b></br></p>
Last cost: <b>0.031571</b>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584378-a514a700-ca62-11e8-8d3d-ed838043334a.PNG"/>
</br>
<h3>Microship Test Using Advanced Optimization methods</h3>
<p>Initial Theta: <b>0.3</b></br>
Iteraion: <b>300</b></br></p>
Lambda: <b>10</b></br></p>
poly: <b>order 2</b></br>
Last cost: <b>0.031571</b>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584395-e5742500-ca62-11e8-8143-4fc5e389bfc3.PNG"/>
</br>
Iteraion: <b>300</b></br></p>
Lambda: <b>10</b></br></p>
poly: <b>order 3</b></br>
Last cost: <b>0.031571</b>
</br>
<img src="https://user-images.githubusercontent.com/20774864/46584394-e5742500-ca62-11e8-9b4a-f0c0141086c9.PNG"/>
</br>
